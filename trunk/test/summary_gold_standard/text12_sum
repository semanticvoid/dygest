A quantum computer would rely on the surreal behaviour of the very small to work miracles with information . The underlying logic of the programs - - the binary choices that control the way a computer counts and calculates - - would work just as well ( if a lot more slowly ) in a device that shuttled ball - bearings instead of electrons . These switches can be thought of as the digits of numbers , in which case their ons and offs are the ones and zeros of binary counting . This is why , by a fortunate contraction of the words " binary digit " , the currency of data processing is known as the " bit " . Indeed , they are organised into " logic gates " that do calculations using this algebra . Paul Benioff , at Argonne National Laboratory , in Illinois , first applied quantum theory to computers in 1981. One of the big advantages of recording and processing information digitally is that it is difficult to make a mistake ( electronic " ones " are not that easily turned into " zeros " ) , and surprisingly easy to design ways to recognise and correct any mistake that is made . 

A quantum computer would rely on the surreal behaviour of the very small to work miracles with information .
What , though , if a computer could be built around a different kind of physics , the quantum physics that governs the weird and uncertain behaviour of atoms and sub - atomic particles ? These switches can be thought of as the digits of numbers , in which case their ons and offs are the ones and zeros of binary counting . This is why , by a fortunate contraction of the words " binary digit " , the currency of data processing is known as the " bit " . Indeed , they are organised into " logic gates " that do calculations using this algebra . Paul Benioff , at Argonne National Laboratory , in Illinois , first applied quantum theory to computers in 1981. Claude Shannon , who also worked at AT&T, set the ball rolling by investigating ways of encoding bits of information so that they would resist errors during transmission down telephone lines . 

A quantum computer would rely on the surreal behaviour of the very small to work miracles with information . Indeed , they are organised into " logic gates " that do calculations using this algebra .
The bits in a " quantum computer " would not , therefore , be ones or zeros . Dr Monroe 's group trapped a single ion ( an atom with missing electrons ) of beryllium , by walling it in with electric and magnetic fields and cooling it to within an ace of absolute zero ( - 273C ) . Why should DARPA , better known for researching missile defences and commissioning the precursor of the Internet , dabble in quantum theory ? Qubits , not being true bits , are not truly digital . One of the big advantages of recording and processing information digitally is that it is difficult to make a mistake ( electronic " ones " are not that easily turned into " zeros " ) , and surprisingly easy to design ways to recognise and correct any mistake that is made . 